{
    "contents" : "######################################################\n###  skeleton Script to sample model posteriors    ###\n###  for a very simple hierarchical linear model   ###\n###  Author:  D.K. Okamoto                         ###\n######################################################\n\nlibrary(ggplot2);library(rstan);library(plyr)\nsetwd(\"~/Dropbox/nceas_kelp_climate_2013/temporal_change/R/analysis_scripts\")\nsource(\"./temporal_kelp_prep.R\")\n\n### min number of sites per study\nmin_sites_study <- 1\n\n### min number of sites per province\nmin_sites_province <- 1\n\n### min number of years per study \nminyears <- 1\n\n rawDataMod2$ProvinceSite <- rawDataMod2$PROVINCE:rawDataMod2$Site\n  \n  ### add julian date\n  rawDataMod2$julian <- julian(rawDataMod2$sasDate)\n\n### format data ###\n\n  ### summarize Study and site info to gather info about lengths\n  data_summary <- ddply(rawDataMod2,.(Study),\n                        summarize,nsites =length(unique(StudySite)))\n  data_summary2 <- ddply(rawDataMod2,.(Study,StudySite,Site),\n                         summarize,nyears =length(unique(year)))\n                         \n  data_summary3 <- ddply(rawDataMod2,.(PROVINCE),\n                        summarize,nsites =length(unique(ProvinceSite)))\n  \n  ### more than minyears years, more than minsites sites ###\n  data_summaryb <- subset(data_summary,nsites>=min_sites_study)\n  data_summary2b <- subset(data_summary2,nyears>=minyears)\n  data_summary3b <- subset(data_summary3,nsites>=min_sites_province)\n \n\n  ### add only data that match the above criteria\n  rawDataMod3 <- subset(rawDataMod2,Study%in%data_summaryb$Study&\n                          StudySite%in%data_summary2b$StudySite&\n                          PROVINCE%in%data_summary3b$PROVINCE)\n\n  ### center julian days for regression\n\n  datsummary <- ddply(rawDataMod2,.(StudySite),summarize,meanjul= mean(julian,na.rm= T))\n  rawDataMod3 <-join(rawDataMod3,datsummary)\n  rawDataMod3$centJul <- (rawDataMod3$julian-rawDataMod3$meanjul)/365.25\n\n  ### get site, study and province number \n  rawDataMod3$SiteN <-  as.numeric(factor(rawDataMod3$StudySite))\n  rawDataMod3$SiteN <-  as.numeric(factor(rawDataMod3$StudySite))\n  rawDataMod3$StudyN <-  as.numeric(factor(rawDataMod3$Study))\n  rawDataMod3$ProvinceN <-  as.numeric(factor(rawDataMod3$PROVINCE))\n  rawDataMod3$ProvinceN <-  as.numeric(factor(rawDataMod3$PROVINCE))\n\n  data2 <- with(rawDataMod3,data.frame(list(x= centJul,Site=SiteN,\n                                            Study= StudyN,Province=ProvinceN,\n                                            Unit= focalUnit,y= stdByPROVINCE)))\n\n### pull out the data for analysis ###\n  x <- data2$x\n  y <- data2$y\n  Site <- data2$Site\n  Study <- data2$Study\n  Province <- data2$Province\n  Unit <- data2$Unit\n  StudySite <- ddply(data2,.(Site),summarize,\n                     StudySite =unique(Study))$StudySite\n  ProvinceSite <- ddply(data2,.(Site),summarize,\n                   ProvinceSite =unique(Province))$ProvinceSite\n\n  NST <- length(unique(data2$Study))\n  NSI <- length(unique(data2$Site))\n  NP <- length(unique(data2$Province))\n  NU <- length(unique(data2$Unit))\n  N <- nrow(data2)\n\n### list of parameters to save ###\nparams<- c(\"beta\",\"beta_mu\",\n           \"sd_e\",\"y_hat\",\n           \"vcov_beta\",\"omega_beta\")\n\n### MCMC details\nn.iter <- 50\nn.burnin <- n.iter/2\nset.seed <- 1234\nn.chains= 3\n\n### data for the model ###\n  data <- list(NST= NP,NSI= NSI,Study=Province,\n               Site= Site,StudySite= ProvinceSite,x=x,y=y,N=N)\n\n### the model ###\nmodel <- \n  '\ndata {\n  int NSI; // number of sites\n  int NST; // number of studies \n  int N; // number of observations\n  vector[N] y; \n  int Site[N]; // vector of length N iding sites\n  int Study[N]; // vector of length N iding studies \n  int StudySite[NSI]; // vector of length NST iding studies by site\n  vector[N] x;\n}\n\nparameters {\n  vector[2] beta[NSI]; // site level slopes\n  vector[2] beta_mu[NST]; // study level slopes\n  vector<lower= 0>[2] sigma_beta[NST]; // ranef variance\n  cholesky_factor_corr[2] omega_beta[NST]; // ranef cholesky factors\n  vector<lower=0>[NST] sd_e; // error variance\n}\n\ntransformed parameters { \n  matrix[2,2] vcov_beta[NST]; // ranef variance-covariance matrix\n  matrix[2,2] D[NST]; // diagonal matrix of ranef SD\n  vector[N] y_hat; // expected value given parameters\n  matrix[2,2] Omega[NST];                      // correlation of RE\n\n  for (k in 1:NST) {  // calculate variance covariance matrix for ranef\n        D[k] <- diag_matrix(sigma_beta[k]);\n        vcov_beta[k] <- D[k] * omega_beta[k];\n        Omega[k] <- tcrossprod(omega_beta[k]);\n  }\n\n  for (i in 1:N){\n    y_hat[i] <- beta[Site[i],1]+beta[Site[i],2]*x[i]; // expectation equation\n  }           \n}\n\nmodel {   \n  \n  for (k in 1:NST) {\n        sigma_beta[k] ~ cauchy(0,2.5); // vague priors for the ranef SD\n        omega_beta[k] ~ lkj_corr_cholesky(1.5); // vague priors for the ranef corr matrix\n  }\n  \n  for (j in 1:NSI) {\n       beta[j] ~ multi_normal_cholesky(beta_mu[StudySite[j]],vcov_beta[StudySite[j]]); // site ranef\n  }\n\n  for (i in 1:N){\n    y[i]~normal(y_hat[i],sd_e[Study[i]]); // likelihood \n  }\n}\n'\n\n### sample the posteriors! ###\n  fit1 <- stan(model_code= model,data= data,pars= params,\n               iter= n.iter,warmup= n.burnin,chains=n.chains,\n               init= \"random\",seed= set.seed)\n\n### extract the posterior samples ###\n  parameters <- extract(fit1)\n\n### function to get median, mean and other quantiles from the posterior ###\n  quant.mean.fun <- function(x) {data.frame(list(mean= mean(x),\n                                               CS_025=quantile(x,probs= 0.025),\n                                               CS_050=quantile(x,probs= 0.050),\n                                               CS_50=quantile(x,probs= 0.50),\n                                               CS_95=quantile(x,probs= 0.95),\n                                               CS_975=quantile(x,probs= 0.975)))\n                                 }\n\n### apply the function to the slopes from each site ###\n  slopes <- data.frame(do.call(\"rbind\",apply(parameters$beta_mu[,,2],2,quant.mean.fun)))\n\n  slopes2 <- data.frame(do.call(\"rbind\",apply(parameters$beta[,,2],2,quant.mean.fun)))\n\n### provide the approprioate province names to each level \n  slopes2$Province <- data$StudySite \n  slopes2$ProvinceName <- factor(slopes2$Province)\n    levels(slopes2$ProvinceName) <- levels(factor(rawDataMod3$PROVINCE))\n  slopes$ProvinceName <-  levels(factor(rawDataMod3$PROVINCE))\n  slopes$ProvMean <- slopes$mu\n  slopes2.order <- slopes2[order(slopes2$Province,slopes2$mean),]\n  slopes2.order$site <- 1:nrow(slopes2.order)\n  slopes$ymin= -Inf\n  slopes$ymax= Inf\n  \n### plot the results ###\n\npdf(width= 8,height= 6,\"Hierarchical_LME/slope_plots2.pdf\")\nggplot(data= slopes2.order)+ \n         geom_rect(aes(xmax= CS_975,xmin= CS_025,ymin= ymin,ymax= ymax),\n            data= slopes,fill= \"pink\",colour=\"pink\")+\n         geom_vline(aes(xintercept=mean),colour= \"red\",data= slopes)+\n         geom_errorbarh(aes(y=site,x=mean,xmin= CS_025,xmax= CS_975),height=0,size= 0.25)+\n         geom_point(aes(y=site,x=mean),size= 0.5,shape= 21,colour= \"black\",fill= \"grey\")+\n           facet_wrap(~ProvinceName,scales= \"free\")+\n         geom_vline(xintercept= 0,size= 0.5)+\n         theme_bw()+\n         theme(panel.grid.minor = element_line(colour = NA),\n\t\t\t   panel.grid.major = element_line(colour = NA))+\n         ylab(\"slope\")\ndev.off()\n\n\n\n",
    "created" : 1424835075756.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "3392241543",
    "id" : "2668F8DB",
    "lastKnownWriteTime" : 1422596328,
    "path" : "~/Dropbox/nceas_kelp_climate_2013/temporal_change/R/analysis_scripts/Hierarchical_LME/Hierarchical_LME.R",
    "project_path" : null,
    "properties" : {
    },
    "source_on_save" : false,
    "type" : "r_source"
}